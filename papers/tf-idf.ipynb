{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency - Inverse Document Frequency\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Tfâ€“idf\n",
    "* http://kak.tx0.org/IR/TFxIDF\n",
    "* https://ecommons.cornell.edu/bitstream/handle/1813/6721/87-881.pdf?sequence=1\n",
    "* http://www.tfidf.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **recall**: the proportion of relevant items retrieved, measured by the ration of the number of relevant retrieved items to the total number of relevant items in the collection\n",
    "* **precision**: the proportion of retrieved items that are relevant, measured by the ration of the number relevant retrieved items to the total number of retrieved items\n",
    "* **TF**: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "<br>\n",
    "`TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).`\n",
    "\n",
    "* **IDF**: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "<br>\n",
    "`IDF(t) = log_e(Total number of documents / Number of documents with term t in it).`\n",
    "\n",
    "* **TF-IDF**: `TF * IDF`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* review scikit-learn's tfidf implementation\n",
    "* return tfidf score between 0 ~ 1 ?\n",
    "* try a more sophisticated tfidf implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import textwrap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(original_text):\n",
    "    original_text = re.sub(r'[~!@#$%^&*()_|+\\-=?;:\",.<>\\{\\}\\[\\]\\\\\\/\\n0-9]',' ',original_text.lower())\n",
    "    original_text = re.sub(r'\\s+',' ',original_text)\n",
    "    return original_text\n",
    "\n",
    "def get_word_counts(document):\n",
    "    word_counts = {}\n",
    "    document_words = document.split(' ')\n",
    "    for w in document_words:\n",
    "        if w in word_counts:\n",
    "            word_counts[w] += 1\n",
    "        else:\n",
    "            word_counts[w] = 1\n",
    "    return word_counts\n",
    "\n",
    "def tf(document_word_counts, word):\n",
    "    if word in document_word_counts:\n",
    "        return document_word_counts[word]\n",
    "    return 0\n",
    "\n",
    "def idf(documents_word_counts, word):\n",
    "    n_of_docs_with_term = 0\n",
    "    for word_counts in documents_word_counts:\n",
    "        if word in word_counts:\n",
    "            n_of_docs_with_term += 1\n",
    "    if n_of_docs_with_term == 0:\n",
    "        return 0\n",
    "\n",
    "    _idf = np.log(len(documents_word_counts) / float(n_of_docs_with_term))\n",
    "    return _idf, n_of_docs_with_term\n",
    "\n",
    "def tf_idf(document_word_counts, documents_word_counts, word):\n",
    "    _tf = tf(document_word_counts, word)\n",
    "    _idf, n_of_docs_with_term = idf(documents_word_counts, word)\n",
    "    return {\n",
    "        'tf': _tf,\n",
    "        'n_of_docs_with_term': n_of_docs_with_term,\n",
    "        'idf': _idf,\n",
    "        'tf_idf': _tf * _idf\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n of documents: 101\n",
      "asian exporters fear damage from u s japan rift mounting trade friction between the u s and japan has raised fears among many of asia's exporting nations that the row could inflict far reaching econom\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corpus_length = 250000\n",
    "reuters_text = clean_text(reuters.raw()[:corpus_length])\n",
    "corpus_length = len(reuters_text)\n",
    "documents = textwrap.wrap(reuters_text, corpus_length / 100)\n",
    "number_of_documents = len(documents)\n",
    "print 'n of documents:', number_of_documents\n",
    "print documents[0][:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tf': 1, 'idf': 2.8233610476132043, 'n_of_docs_with_term': 6, 'tf_idf': 2.8233610476132043}\n",
      "{'tf': 1, 'idf': 3.5165082281731497, 'n_of_docs_with_term': 3, 'tf_idf': 3.5165082281731497}\n",
      "{'tf': 7, 'idf': 1.0042026041970351, 'n_of_docs_with_term': 37, 'tf_idf': 7.029418229379246}\n",
      "{'tf': 1, 'idf': 4.6151205168412597, 'n_of_docs_with_term': 1, 'tf_idf': 4.6151205168412597}\n",
      "{'tf': 1, 'idf': 4.6151205168412597, 'n_of_docs_with_term': 1, 'tf_idf': 4.6151205168412597}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "documents_word_counts = [get_word_counts(d) for d in documents]\n",
    "\n",
    "print tf_idf(documents_word_counts[0], documents_word_counts, 'nations')\n",
    "print tf_idf(documents_word_counts[0], documents_word_counts, 'mounting')\n",
    "print tf_idf(documents_word_counts[0], documents_word_counts, 'trade')\n",
    "print tf_idf(documents_word_counts[0], documents_word_counts, 'row')\n",
    "print tf_idf(documents_word_counts[0], documents_word_counts, 'inflict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
