{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directed acyclic graph\n",
    "\n",
    "https://en.wikipedia.org/wiki/Directed_acyclic_graph\n",
    "\n",
    "https://www.youtube.com/watch?v=LOr_abIZL04\n",
    "\n",
    "### Used In\n",
    "* https://github.com/fxsjy/jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/dag1.png\" width=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation on Chinese sentence\n",
    "\n",
    "### TODO\n",
    "* what is the use of this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def print_pretty_json(dic):\n",
    "#     parsed = json.loads(dic)\n",
    "    print json.dumps(dic, indent=2, sort_keys=False, ensure_ascii=False).encode('utf8')\n",
    "    \n",
    "def does_dag_has(DAG, rng):\n",
    "    for n in DAG:\n",
    "        if DAG[n]['range'] == rng:\n",
    "            return n\n",
    "    return -1\n",
    "\n",
    "def add_dag_2(DAG, sentence, rng, req, FREQ):\n",
    "    d = len(DAG)\n",
    "#     d = sentence[rng[0]:rng[1]]\n",
    "    index = does_dag_has(DAG, rng)\n",
    "    word = sentence[rng[0]:rng[1]]\n",
    "    word_p = sentence[rng[0]-1:rng[1]]\n",
    "    \n",
    "    rel = -1\n",
    "    if word_p in FREQ:\n",
    "        rel = FREQ[word_p]\n",
    "    \n",
    "    if index == -1:\n",
    "        r = []\n",
    "        if req:\n",
    "            r = [req]\n",
    "        \n",
    "        DAG[d] = {\n",
    "            'range': rng,\n",
    "            'word': word,\n",
    "            'req': r,\n",
    "            'rel': rel\n",
    "        }\n",
    "        return DAG\n",
    "\n",
    "    if req not in DAG[index]['req']:\n",
    "        DAG[index]['req'].append(req)\n",
    "    \n",
    "    return DAG\n",
    "\n",
    "def generate_dag_rec(DAG, sentence, FREQ, depth=0, padding=0, prev=None):\n",
    "    N = len(sentence)\n",
    "    for i in range(depth,N):\n",
    "#         print depth + padding, i+1, sentence[depth+padding:i+1]\n",
    "        if depth + padding >= i+1:\n",
    "            continue\n",
    "        \n",
    "        if sentence[depth+padding:i+1] in FREQ:\n",
    "            DAG = add_dag_2(DAG, sentence, [depth+padding, i+1], prev, FREQ)\n",
    "#         print depth, padding, i+1, sentence[depth+padding:i+1], sentence[depth+padding:i+1] in FREQ\n",
    "#         if sentence[depth+padding:i+1] in FREQ:\n",
    "            generate_dag_rec(DAG, sentence, FREQ, depth+1, i+1-depth-1, sentence[depth+padding:i+1])\n",
    "\n",
    "def generate_dag(sentence, FREQ):\n",
    "    DAG = {}\n",
    "    generate_dag_rec(DAG, sentence, FREQ)\n",
    "    return DAG\n",
    "\n",
    "def remove_key(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "def get_removable_keys(DAG):\n",
    "    keys = []\n",
    "    for d in DAG:\n",
    "        if len(DAG[d]['req']) == 0:\n",
    "            keys.append(d)\n",
    "    return keys\n",
    "\n",
    "def remove_node_from_dag(DAG):\n",
    "    key = get_removable_keys(DAG)[0]\n",
    "    DAG = remove_key(DAG, key)\n",
    "    for d in DAG:\n",
    "        if key in DAG[d]['req']:\n",
    "            req = [r for r in DAG[d]['req'] if r != key]\n",
    "            DAG[d]['req'] = req\n",
    "    return DAG, key\n",
    "\n",
    "def get_possible_node(DAG, key=None):\n",
    "    \n",
    "    if key == None:\n",
    "        return get_removable_keys(DAG)\n",
    "    \n",
    "    keyy= DAG[key]['word']\n",
    "    \n",
    "    nodes = []\n",
    "    for d in DAG:\n",
    "        if keyy in DAG[d]['req']:\n",
    "            nodes.append(d)\n",
    "    return nodes\n",
    "\n",
    "def generate_path_stack(DAG):\n",
    "    stack = []\n",
    "    pp = get_possible_node(DAG, None)\n",
    "    def generate_path_stack_rec(DAG, pp, stack):\n",
    "\n",
    "        if len(pp) > 1:\n",
    "            stack.append('BRANCH')\n",
    "\n",
    "        for i in range(len(pp)):\n",
    "            stack.append(pp[i])\n",
    "            ppp = get_possible_node(DAG, pp[i])\n",
    "            if len(ppp) > 0:\n",
    "                generate_path_stack_rec(DAG, ppp, stack)\n",
    "            else:\n",
    "                stack.append('END')\n",
    "        return stack\n",
    "\n",
    "    stack = generate_path_stack_rec(DAG, pp, stack)\n",
    "    return stack\n",
    "\n",
    "\n",
    "def get_possible_paths(stack):\n",
    "    sents = []\n",
    "    prev_branch = 0\n",
    "    prev_sent = u''\n",
    "    sent = u''\n",
    "    for i, c in enumerate(stack):\n",
    "        if c == 'BRANCH':\n",
    "            prev_sent = stack[prev_branch+1:i]\n",
    "            prev_branch = i\n",
    "        if c == 'END':\n",
    "            sent = stack[prev_branch+1:i]\n",
    "            sents.append(prev_sent + sent)\n",
    "            prev_branch = i\n",
    "\n",
    "    readable_sents = []\n",
    "    for ss in sents:\n",
    "        readable_sents.append([DAG[s]['word'] for s in ss])\n",
    "\n",
    "    return sents, readable_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"0\": {\n",
      "    \"range\": [\n",
      "      0, \n",
      "      1\n",
      "    ], \n",
      "    \"req\": [], \n",
      "    \"word\": \"你\", \n",
      "    \"rel\": -1\n",
      "  }, \n",
      "  \"1\": {\n",
      "    \"range\": [\n",
      "      1, \n",
      "      2\n",
      "    ], \n",
      "    \"req\": [\n",
      "      \"你\"\n",
      "    ], \n",
      "    \"word\": \"好\", \n",
      "    \"rel\": 32\n",
      "  }, \n",
      "  \"2\": {\n",
      "    \"range\": [\n",
      "      2, \n",
      "      3\n",
      "    ], \n",
      "    \"req\": [\n",
      "      \"好\", \n",
      "      \"你好\"\n",
      "    ], \n",
      "    \"word\": \"吗\", \n",
      "    \"rel\": -1\n",
      "  }, \n",
      "  \"3\": {\n",
      "    \"range\": [\n",
      "      3, \n",
      "      4\n",
      "    ], \n",
      "    \"req\": [\n",
      "      \"吗\"\n",
      "    ], \n",
      "    \"word\": \"我\", \n",
      "    \"rel\": -1\n",
      "  }, \n",
      "  \"4\": {\n",
      "    \"range\": [\n",
      "      4, \n",
      "      5\n",
      "    ], \n",
      "    \"req\": [\n",
      "      \"我\"\n",
      "    ], \n",
      "    \"word\": \"名\", \n",
      "    \"rel\": -1\n",
      "  }, \n",
      "  \"5\": {\n",
      "    \"range\": [\n",
      "      5, \n",
      "      6\n",
      "    ], \n",
      "    \"req\": [\n",
      "      \"名\"\n",
      "    ], \n",
      "    \"word\": \"字\", \n",
      "    \"rel\": 5\n",
      "  }, \n",
      "  \"6\": {\n",
      "    \"range\": [\n",
      "      6, \n",
      "      7\n",
      "    ], \n",
      "    \"req\": [\n",
      "      \"字\", \n",
      "      \"名字\"\n",
      "    ], \n",
      "    \"word\": \"叫\", \n",
      "    \"rel\": -1\n",
      "  }, \n",
      "  \"7\": {\n",
      "    \"range\": [\n",
      "      4, \n",
      "      6\n",
      "    ], \n",
      "    \"req\": [\n",
      "      \"我\"\n",
      "    ], \n",
      "    \"word\": \"名字\", \n",
      "    \"rel\": -1\n",
      "  }, \n",
      "  \"8\": {\n",
      "    \"range\": [\n",
      "      0, \n",
      "      2\n",
      "    ], \n",
      "    \"req\": [], \n",
      "    \"word\": \"你好\", \n",
      "    \"rel\": -1\n",
      "  }\n",
      "}\n",
      "[\n",
      "  \"BRANCH\", \n",
      "  0, \n",
      "  1, \n",
      "  2, \n",
      "  3, \n",
      "  \"BRANCH\", \n",
      "  4, \n",
      "  5, \n",
      "  6, \n",
      "  \"END\", \n",
      "  7, \n",
      "  6, \n",
      "  \"END\", \n",
      "  8, \n",
      "  2, \n",
      "  3, \n",
      "  \"BRANCH\", \n",
      "  4, \n",
      "  5, \n",
      "  6, \n",
      "  \"END\", \n",
      "  7, \n",
      "  6, \n",
      "  \"END\"\n",
      "]\n",
      "[\n",
      "  [\n",
      "    0, \n",
      "    1, \n",
      "    2, \n",
      "    3, \n",
      "    4, \n",
      "    5, \n",
      "    6\n",
      "  ], \n",
      "  [\n",
      "    0, \n",
      "    1, \n",
      "    2, \n",
      "    3, \n",
      "    7, \n",
      "    6\n",
      "  ], \n",
      "  [\n",
      "    8, \n",
      "    2, \n",
      "    3, \n",
      "    4, \n",
      "    5, \n",
      "    6\n",
      "  ], \n",
      "  [\n",
      "    8, \n",
      "    2, \n",
      "    3, \n",
      "    7, \n",
      "    6\n",
      "  ]\n",
      "]\n",
      "[\n",
      "  [\n",
      "    \"你\", \n",
      "    \"好\", \n",
      "    \"吗\", \n",
      "    \"我\", \n",
      "    \"名\", \n",
      "    \"字\", \n",
      "    \"叫\"\n",
      "  ], \n",
      "  [\n",
      "    \"你\", \n",
      "    \"好\", \n",
      "    \"吗\", \n",
      "    \"我\", \n",
      "    \"名字\", \n",
      "    \"叫\"\n",
      "  ], \n",
      "  [\n",
      "    \"你好\", \n",
      "    \"吗\", \n",
      "    \"我\", \n",
      "    \"名\", \n",
      "    \"字\", \n",
      "    \"叫\"\n",
      "  ], \n",
      "  [\n",
      "    \"你好\", \n",
      "    \"吗\", \n",
      "    \"我\", \n",
      "    \"名字\", \n",
      "    \"叫\"\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# FREQ = [u'你', u'你好', u'好', u'吗', u'我', u'名', u'字', u'名字', u'叫']\n",
    "\n",
    "FREQ = {\n",
    "    u'你':   12,\n",
    "    u'你好': 32,\n",
    "    u'好':   1,\n",
    "    u'吗':   4,\n",
    "    u'我':   6,\n",
    "    u'名':   9,\n",
    "    u'字':   3,\n",
    "    u'名字': 5,\n",
    "    u'叫':   9,\n",
    "}\n",
    "\n",
    "\n",
    "sentence = u'你好吗我名字叫'\n",
    "\n",
    "DAG = generate_dag(sentence, FREQ)\n",
    "stack = generate_path_stack(DAG)\n",
    "path_nodes, path_words = get_possible_paths(stack)\n",
    "\n",
    "print_pretty_json(DAG)\n",
    "print_pretty_json(stack)\n",
    "print_pretty_json(path_nodes)\n",
    "print_pretty_json(path_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"到\", \n",
      "  \"底\", \n",
      "  \"认\", \n",
      "  \"识\", \n",
      "  \"不\", \n",
      "  \"认识\", \n",
      "  \"到底\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_words_from_dag(DAG, FREQ=None):\n",
    "    words = []\n",
    "    for k in DAG:\n",
    "        if FREQ != None:\n",
    "            if DAG[k]['word'] in FREQ:          \n",
    "                if DAG[k]['word'] not in words:\n",
    "                    words.append(DAG[k]['word'])\n",
    "        else:\n",
    "            if DAG[k]['word'] not in words:\n",
    "                words.append(DAG[k]['word'])\n",
    "    return words\n",
    "\n",
    "# freeq = [u'你', u'名字']\n",
    "\n",
    "print_pretty_json(get_words_from_dag(DAG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_file = './dict/dict.txt.small'\n",
    "f = open(dict_file, 'r+')\n",
    "\n",
    "FREQ = {}\n",
    "c = 0\n",
    "while c < 100000:\n",
    "    c += 1\n",
    "    line = next(f)\n",
    "    line = line.split(' ')\n",
    "    key = unicode(line[0], 'utf-8')\n",
    "    FREQ[key] = line[1]\n",
    "    \n",
    "# print_pretty_json(FREQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"门口\", \n",
      "  \"天安\", \n",
      "  \"天安门\", \n",
      "  \"地方\", \n",
      "  \"这个\", \n",
      "  \"认识\", \n",
      "  \"到底\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentence = u'到底认识不认识这个地方天安门口'\n",
    "# sentence = u'到底认识不认识我啊我住在这里住了很久了我最喜欢的是上海这里的食堂天安门也不错不过哪个在北京'\n",
    "DAG = generate_dag(sentence, FREQ)\n",
    "# stack = generate_path_stack(DAG)\n",
    "# path_nodes, path_words = get_possible_paths(stack)\n",
    "\n",
    "# print_pretty_json(DAG)\n",
    "xx = [i for i in get_words_from_dag(DAG, FREQ) if len(i) > 1]\n",
    "print_pretty_json(xx)\n",
    "\n",
    "# print_pretty_json(DAG)\n",
    "# print_pretty_json(stack)\n",
    "# print_pretty_json(path_nodes)\n",
    "# print_pretty_json(path_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
